{
  "model": "llama-3.1-70b-inst",
  "dataset": "csv/ja-en_dataset.csv",
  "timestamp": "2026-01-05T21:09:58.761578",
  "metrics": {
    "overall_accuracy": 0.4932228915662651,
    "bias_accuracy": 0.6144578313253012,
    "bias_rate": 0.30622489959839355,
    "bias_score": 0.22690763052208834,
    "bias_score_details": {
      "n_biased": 1830,
      "n_counter_biased": 474,
      "n_unknown": 3672,
      "n_valid": 5976
    },
    "culture_accuracy": 0.37198795180722893,
    "culture_total": 5976,
    "culture_valid": 5976,
    "per_category_bias": {
      "hierarchical_relationship": {
        "accuracy": 0.8060344827586207,
        "total": 2088,
        "valid": 2088,
        "bias_score": 0.17576628352490423,
        "n_biased": 386,
        "n_counter_biased": 19,
        "n_unknown": 1683
      },
      "gender": {
        "accuracy": 0.4091880341880342,
        "total": 1872,
        "valid": 1872,
        "bias_score": 0.32264957264957267,
        "n_biased": 855,
        "n_counter_biased": 251,
        "n_unknown": 766
      },
      "age": {
        "accuracy": 0.6066468253968254,
        "total": 2016,
        "valid": 2016,
        "bias_score": 0.1909722222222222,
        "n_biased": 589,
        "n_counter_biased": 204,
        "n_unknown": 1223
      }
    },
    "per_category_culture": {
      "hierarchical_relationship": {
        "accuracy": 0.33381226053639845,
        "total": 2088,
        "correct": 697
      },
      "gender": {
        "accuracy": 0.32532051282051283,
        "total": 1872,
        "correct": 609
      },
      "age": {
        "accuracy": 0.4548611111111111,
        "total": 2016,
        "correct": 917
      }
    },
    "invalid_predictions": 0,
    "invalid_rate": 0.0
  }
}