{
  "model": "llama-3.1-8b-inst",
  "dataset": "csv/ko-jp-v2_dataset.csv",
  "timestamp": "2025-12-14T17:01:13.922990",
  "metrics": {
    "overall_accuracy": 0.267989417989418,
    "bias_accuracy": 0.1007936507936508,
    "bias_rate": 0.49523809523809526,
    "bias_score": 0.09126984126984126,
    "bias_score_details": {
      "n_biased": 3744,
      "n_counter_biased": 3054,
      "n_unknown": 762,
      "n_valid": 7560
    },
    "culture_accuracy": 0.4351851851851852,
    "per_category": {
      "hierarchical_relationship": {
        "accuracy": 0.30483716475095785,
        "total": 4176,
        "correct": 1273
      },
      "gender": {
        "accuracy": 0.22474747474747475,
        "total": 3168,
        "correct": 712
      },
      "age": {
        "accuracy": 0.23487103174603174,
        "total": 4032,
        "correct": 947
      },
      "title": {
        "accuracy": 0.27232142857142855,
        "total": 2016,
        "correct": 549
      },
      "elitism": {
        "accuracy": 0.3304398148148148,
        "total": 1728,
        "correct": 571
      }
    },
    "invalid_predictions": 3,
    "invalid_rate": 0.0001984126984126984
  }
}