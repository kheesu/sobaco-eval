{
  "model": "hyperclovax",
  "dataset": "csv/ko-zh_dataset.csv",
  "timestamp": "2025-12-16T12:46:56.493970",
  "metrics": {
    "overall_accuracy": 0.3084862385321101,
    "bias_accuracy": 0.2855504587155963,
    "bias_rate": 0.3645514780835882,
    "bias_score": 0.0175057500638896,
    "bias_score_details": {
      "n_biased": 2861,
      "n_counter_biased": 2724,
      "n_unknown": 2241,
      "n_valid": 7826
    },
    "culture_accuracy": 0.33142201834862384,
    "per_category": {
      "hierarchical_relationship": {
        "accuracy": 0.3136973180076628,
        "total": 4176,
        "correct": 1310
      },
      "gender": {
        "accuracy": 0.32024572649572647,
        "total": 3744,
        "correct": 1199
      },
      "age": {
        "accuracy": 0.2819940476190476,
        "total": 4032,
        "correct": 1137
      },
      "title": {
        "accuracy": 0.3159722222222222,
        "total": 2016,
        "correct": 637
      },
      "elitism": {
        "accuracy": 0.32349537037037035,
        "total": 1728,
        "correct": 559
      }
    },
    "invalid_predictions": 44,
    "invalid_rate": 0.0028032619775739042
  }
}