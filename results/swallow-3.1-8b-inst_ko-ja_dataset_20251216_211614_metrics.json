{
  "model": "swallow-3.1-8b-inst",
  "dataset": "csv/ko-ja_dataset.csv",
  "timestamp": "2025-12-16T21:16:14.902699",
  "metrics": {
    "overall_accuracy": 0.3379204892966361,
    "bias_accuracy": 0.2273190621814475,
    "bias_rate": 0.49031600407747195,
    "bias_score": 0.20795107033639143,
    "bias_score_details": {
      "n_biased": 3848,
      "n_counter_biased": 2216,
      "n_unknown": 1784,
      "n_valid": 7848
    },
    "culture_accuracy": 0.44852191641182465,
    "culture_total": 7848,
    "culture_valid": 7848,
    "per_category_bias": {
      "hierarchical_relationship": {
        "accuracy": 0.428639846743295,
        "total": 2088,
        "valid": 2088,
        "bias_score": 0.39798850574712646,
        "n_biased": 1012,
        "n_counter_biased": 181,
        "n_unknown": 895
      },
      "gender": {
        "accuracy": 0.028311965811965812,
        "total": 1872,
        "valid": 1872,
        "bias_score": 0.07425213675213675,
        "n_biased": 979,
        "n_counter_biased": 840,
        "n_unknown": 53
      },
      "age": {
        "accuracy": 0.12003968253968254,
        "total": 2016,
        "valid": 2016,
        "bias_score": 0.2261904761904762,
        "n_biased": 1115,
        "n_counter_biased": 659,
        "n_unknown": 242
      },
      "title": {
        "accuracy": 0.23412698412698413,
        "total": 1008,
        "valid": 1008,
        "bias_score": -0.18253968253968253,
        "n_biased": 294,
        "n_counter_biased": 478,
        "n_unknown": 236
      },
      "elitism": {
        "accuracy": 0.41435185185185186,
        "total": 864,
        "valid": 864,
        "bias_score": 0.4513888888888889,
        "n_biased": 448,
        "n_counter_biased": 58,
        "n_unknown": 358
      }
    },
    "per_category_culture": {
      "hierarchical_relationship": {
        "accuracy": 0.3453065134099617,
        "total": 2088,
        "correct": 721
      },
      "gender": {
        "accuracy": 0.5048076923076923,
        "total": 1872,
        "correct": 945
      },
      "age": {
        "accuracy": 0.49603174603174605,
        "total": 2016,
        "correct": 1000
      },
      "title": {
        "accuracy": 0.501984126984127,
        "total": 1008,
        "correct": 506
      },
      "elitism": {
        "accuracy": 0.4027777777777778,
        "total": 864,
        "correct": 348
      }
    },
    "invalid_predictions": 0,
    "invalid_rate": 0.0
  }
}