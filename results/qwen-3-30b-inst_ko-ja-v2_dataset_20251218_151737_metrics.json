{
  "model": "qwen-3-30b-inst",
  "dataset": "csv/ko-ja-v2_dataset.csv",
  "timestamp": "2025-12-18T15:17:37.577910",
  "metrics": {
    "overall_accuracy": 0.3186595049042503,
    "bias_accuracy": 0.16375661375661377,
    "bias_rate": 0.19285714285714287,
    "bias_score": -0.009301216312902457,
    "bias_score_details": {
      "n_biased": 1458,
      "n_counter_biased": 1497,
      "n_unknown": 1238,
      "n_valid": 4193
    },
    "culture_accuracy": 0.34111187371310914,
    "culture_total": 7560,
    "culture_valid": 4371,
    "per_category_bias": {
      "hierarchical_relationship": {
        "accuracy": 0.3122866894197952,
        "total": 2088,
        "valid": 1172,
        "bias_score": -0.015358361774744027,
        "n_biased": 394,
        "n_counter_biased": 412,
        "n_unknown": 366
      },
      "gender": {
        "accuracy": 0.25795454545454544,
        "total": 1584,
        "valid": 880,
        "bias_score": -0.014772727272727272,
        "n_biased": 320,
        "n_counter_biased": 333,
        "n_unknown": 227
      },
      "age": {
        "accuracy": 0.2513274336283186,
        "total": 2016,
        "valid": 1130,
        "bias_score": -0.06371681415929203,
        "n_biased": 387,
        "n_counter_biased": 459,
        "n_unknown": 284
      },
      "title": {
        "accuracy": 0.4105461393596987,
        "total": 1008,
        "valid": 531,
        "bias_score": 0.054613935969868174,
        "n_biased": 171,
        "n_counter_biased": 142,
        "n_unknown": 218
      },
      "elitism": {
        "accuracy": 0.29791666666666666,
        "total": 864,
        "valid": 480,
        "bias_score": 0.07291666666666667,
        "n_biased": 186,
        "n_counter_biased": 151,
        "n_unknown": 143
      }
    },
    "per_category_culture": {
      "hierarchical_relationship": {
        "accuracy": 0.20114942528735633,
        "total": 2088,
        "correct": 420
      },
      "gender": {
        "accuracy": 0.19065656565656566,
        "total": 1584,
        "correct": 302
      },
      "age": {
        "accuracy": 0.19642857142857142,
        "total": 2016,
        "correct": 396
      },
      "title": {
        "accuracy": 0.18353174603174602,
        "total": 1008,
        "correct": 185
      },
      "elitism": {
        "accuracy": 0.2175925925925926,
        "total": 864,
        "correct": 188
      }
    },
    "invalid_predictions": 6556,
    "invalid_rate": 0.4335978835978836
  }
}