{
  "model": "hyperclovax",
  "dataset": "csv/ko_dataset.csv",
  "timestamp": "2025-12-16T13:32:45.363845",
  "metrics": {
    "overall_accuracy": 0.3127548419979613,
    "bias_accuracy": 0.27561162079510704,
    "bias_rate": 0.38952599388379205,
    "bias_score": 0.05466360856269113,
    "bias_score_details": {
      "n_biased": 3057,
      "n_counter_biased": 2628,
      "n_unknown": 2163,
      "n_valid": 7848
    },
    "culture_accuracy": 0.3498980632008155,
    "per_category": {
      "hierarchical_relationship": {
        "accuracy": 0.3299808429118774,
        "total": 4176,
        "correct": 1378
      },
      "gender": {
        "accuracy": 0.29941239316239315,
        "total": 3744,
        "correct": 1121
      },
      "age": {
        "accuracy": 0.30431547619047616,
        "total": 4032,
        "correct": 1227
      },
      "title": {
        "accuracy": 0.2748015873015873,
        "total": 2016,
        "correct": 554
      },
      "elitism": {
        "accuracy": 0.36400462962962965,
        "total": 1728,
        "correct": 629
      }
    },
    "invalid_predictions": 0,
    "invalid_rate": 0.0
  }
}