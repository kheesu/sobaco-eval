{
  "model": "qwen-3-4b-inst",
  "dataset": "csv/ko-zh-v2_dataset.csv",
  "timestamp": "2026-01-03T17:12:06.617376",
  "metrics": {
    "overall_accuracy": 0.3630952380952381,
    "bias_accuracy": 0.33134920634920634,
    "bias_rate": 0.425,
    "bias_score": 0.18134920634920634,
    "bias_score_details": {
      "n_biased": 3213,
      "n_counter_biased": 1842,
      "n_unknown": 2505,
      "n_valid": 7560
    },
    "culture_accuracy": 0.3948412698412698,
    "culture_total": 7560,
    "culture_valid": 7560,
    "per_category_bias": {
      "hierarchical_relationship": {
        "accuracy": 0.43773946360153254,
        "total": 2088,
        "valid": 2088,
        "bias_score": 0.3773946360153257,
        "n_biased": 981,
        "n_counter_biased": 193,
        "n_unknown": 914
      },
      "gender": {
        "accuracy": 0.26641414141414144,
        "total": 1584,
        "valid": 1584,
        "bias_score": 0.09343434343434344,
        "n_biased": 655,
        "n_counter_biased": 507,
        "n_unknown": 422
      },
      "age": {
        "accuracy": 0.13293650793650794,
        "total": 2016,
        "valid": 2016,
        "bias_score": 0.3323412698412698,
        "n_biased": 1209,
        "n_counter_biased": 539,
        "n_unknown": 268
      },
      "title": {
        "accuracy": 0.07242063492063493,
        "total": 1008,
        "valid": 1008,
        "bias_score": -0.2648809523809524,
        "n_biased": 334,
        "n_counter_biased": 601,
        "n_unknown": 73
      },
      "elitism": {
        "accuracy": 0.9583333333333334,
        "total": 864,
        "valid": 864,
        "bias_score": 0.037037037037037035,
        "n_biased": 34,
        "n_counter_biased": 2,
        "n_unknown": 828
      }
    },
    "per_category_culture": {
      "hierarchical_relationship": {
        "accuracy": 0.36733716475095785,
        "total": 2088,
        "correct": 767
      },
      "gender": {
        "accuracy": 0.3162878787878788,
        "total": 1584,
        "correct": 501
      },
      "age": {
        "accuracy": 0.3368055555555556,
        "total": 2016,
        "correct": 679
      },
      "title": {
        "accuracy": 0.6944444444444444,
        "total": 1008,
        "correct": 700
      },
      "elitism": {
        "accuracy": 0.3912037037037037,
        "total": 864,
        "correct": 338
      }
    },
    "invalid_predictions": 0,
    "invalid_rate": 0.0
  }
}