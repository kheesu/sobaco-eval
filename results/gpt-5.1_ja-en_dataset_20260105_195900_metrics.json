{
  "model": "gpt-5.1",
  "dataset": "csv/ja-en_dataset.csv",
  "timestamp": "2026-01-05T19:59:00.133706",
  "metrics": {
    "overall_accuracy": 0.6095214190093708,
    "bias_accuracy": 0.7622155287817939,
    "bias_rate": 0.1757028112449799,
    "bias_score": 0.11362115127175368,
    "bias_score_details": {
      "n_biased": 1050,
      "n_counter_biased": 371,
      "n_unknown": 4555,
      "n_valid": 5976
    },
    "culture_accuracy": 0.4568273092369478,
    "culture_total": 5976,
    "culture_valid": 5976,
    "per_category_bias": {
      "hierarchical_relationship": {
        "accuracy": 0.9645593869731801,
        "total": 2088,
        "valid": 2088,
        "bias_score": 0.034482758620689655,
        "n_biased": 73,
        "n_counter_biased": 1,
        "n_unknown": 2014
      },
      "gender": {
        "accuracy": 0.7361111111111112,
        "total": 1872,
        "valid": 1872,
        "bias_score": 0.05235042735042735,
        "n_biased": 296,
        "n_counter_biased": 198,
        "n_unknown": 1378
      },
      "age": {
        "accuracy": 0.5768849206349206,
        "total": 2016,
        "valid": 2016,
        "bias_score": 0.2524801587301587,
        "n_biased": 681,
        "n_counter_biased": 172,
        "n_unknown": 1163
      }
    },
    "per_category_culture": {
      "hierarchical_relationship": {
        "accuracy": 0.37691570881226055,
        "total": 2088,
        "correct": 787
      },
      "gender": {
        "accuracy": 0.3488247863247863,
        "total": 1872,
        "correct": 653
      },
      "age": {
        "accuracy": 0.6398809523809523,
        "total": 2016,
        "correct": 1290
      }
    },
    "invalid_predictions": 0,
    "invalid_rate": 0.0
  }
}