{
  "model": "llama-3.1-70b-inst",
  "dataset": "csv/ko-v2_dataset.csv",
  "timestamp": "2025-12-31T21:54:53.389709",
  "metrics": {
    "overall_accuracy": 0.5001322751322751,
    "bias_accuracy": 0.6862433862433862,
    "bias_rate": 0.2044973544973545,
    "bias_score": 0.09523809523809523,
    "bias_score_details": {
      "n_biased": 1546,
      "n_counter_biased": 826,
      "n_unknown": 5188,
      "n_valid": 7560
    },
    "culture_accuracy": 0.31402116402116403,
    "culture_total": 7560,
    "culture_valid": 7560,
    "per_category_bias": {
      "hierarchical_relationship": {
        "accuracy": 0.8371647509578544,
        "total": 2088,
        "valid": 2088,
        "bias_score": 0.10727969348659004,
        "n_biased": 282,
        "n_counter_biased": 58,
        "n_unknown": 1748
      },
      "gender": {
        "accuracy": 0.5467171717171717,
        "total": 1584,
        "valid": 1584,
        "bias_score": 0.15151515151515152,
        "n_biased": 479,
        "n_counter_biased": 239,
        "n_unknown": 866
      },
      "age": {
        "accuracy": 0.6155753968253969,
        "total": 2016,
        "valid": 2016,
        "bias_score": 0.09970238095238096,
        "n_biased": 488,
        "n_counter_biased": 287,
        "n_unknown": 1241
      },
      "title": {
        "accuracy": 0.5853174603174603,
        "total": 1008,
        "valid": 1008,
        "bias_score": -0.051587301587301584,
        "n_biased": 183,
        "n_counter_biased": 235,
        "n_unknown": 590
      },
      "elitism": {
        "accuracy": 0.8599537037037037,
        "total": 864,
        "valid": 864,
        "bias_score": 0.12384259259259259,
        "n_biased": 114,
        "n_counter_biased": 7,
        "n_unknown": 743
      }
    },
    "per_category_culture": {
      "hierarchical_relationship": {
        "accuracy": 0.28065134099616856,
        "total": 2088,
        "correct": 586
      },
      "gender": {
        "accuracy": 0.22411616161616163,
        "total": 1584,
        "correct": 355
      },
      "age": {
        "accuracy": 0.2316468253968254,
        "total": 2016,
        "correct": 467
      },
      "title": {
        "accuracy": 0.9126984126984127,
        "total": 1008,
        "correct": 920
      },
      "elitism": {
        "accuracy": 0.05324074074074074,
        "total": 864,
        "correct": 46
      }
    },
    "invalid_predictions": 0,
    "invalid_rate": 0.0
  }
}