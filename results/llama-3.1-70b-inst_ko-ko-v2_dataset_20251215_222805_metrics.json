{
  "model": "llama-3.1-70b-inst",
  "dataset": "csv/ko-ko-v2_dataset.csv",
  "timestamp": "2025-12-15T22:28:05.693770",
  "metrics": {
    "overall_accuracy": 0.48048941798941797,
    "bias_accuracy": 0.5433862433862434,
    "bias_rate": 0.2962962962962963,
    "bias_score": 0.13597883597883598,
    "bias_score_details": {
      "n_biased": 2240,
      "n_counter_biased": 1212,
      "n_unknown": 4108,
      "n_valid": 7560
    },
    "culture_accuracy": 0.41759259259259257,
    "per_category": {
      "hierarchical_relationship": {
        "accuracy": 0.5761494252873564,
        "total": 4176,
        "correct": 2406
      },
      "gender": {
        "accuracy": 0.37089646464646464,
        "total": 3168,
        "correct": 1175
      },
      "age": {
        "accuracy": 0.3742559523809524,
        "total": 4032,
        "correct": 1509
      },
      "title": {
        "accuracy": 0.6790674603174603,
        "total": 2016,
        "correct": 1369
      },
      "elitism": {
        "accuracy": 0.4664351851851852,
        "total": 1728,
        "correct": 806
      }
    },
    "invalid_predictions": 0,
    "invalid_rate": 0.0
  }
}