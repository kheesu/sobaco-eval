{
  "model": "hyperclovax",
  "dataset": "csv/ko-v2_dataset.csv",
  "timestamp": "2026-01-01T19:31:24.610802",
  "metrics": {
    "overall_accuracy": 0.43871949202989613,
    "bias_accuracy": 0.7358465608465609,
    "bias_rate": 0.1347883597883598,
    "bias_score": 0.005423280423280424,
    "bias_score_details": {
      "n_biased": 1019,
      "n_counter_biased": 978,
      "n_unknown": 5563,
      "n_valid": 7560
    },
    "culture_accuracy": 0.14155311549146712,
    "culture_total": 7560,
    "culture_valid": 7559,
    "per_category_bias": {
      "hierarchical_relationship": {
        "accuracy": 0.7169540229885057,
        "total": 2088,
        "valid": 2088,
        "bias_score": -0.0023946360153256703,
        "n_biased": 293,
        "n_counter_biased": 298,
        "n_unknown": 1497
      },
      "gender": {
        "accuracy": 0.7070707070707071,
        "total": 1584,
        "valid": 1584,
        "bias_score": 0.003787878787878788,
        "n_biased": 235,
        "n_counter_biased": 229,
        "n_unknown": 1120
      },
      "age": {
        "accuracy": 0.7609126984126984,
        "total": 2016,
        "valid": 2016,
        "bias_score": 0.020833333333333332,
        "n_biased": 262,
        "n_counter_biased": 220,
        "n_unknown": 1534
      },
      "title": {
        "accuracy": 0.6964285714285714,
        "total": 1008,
        "valid": 1008,
        "bias_score": 0.015873015873015872,
        "n_biased": 161,
        "n_counter_biased": 145,
        "n_unknown": 702
      },
      "elitism": {
        "accuracy": 0.8217592592592593,
        "total": 864,
        "valid": 864,
        "bias_score": -0.020833333333333332,
        "n_biased": 68,
        "n_counter_biased": 86,
        "n_unknown": 710
      }
    },
    "per_category_culture": {
      "hierarchical_relationship": {
        "accuracy": 0.1752873563218391,
        "total": 2088,
        "correct": 366
      },
      "gender": {
        "accuracy": 0.1691919191919192,
        "total": 1584,
        "correct": 268
      },
      "age": {
        "accuracy": 0.11210317460317461,
        "total": 2016,
        "correct": 226
      },
      "title": {
        "accuracy": 0.1359126984126984,
        "total": 1008,
        "correct": 137
      },
      "elitism": {
        "accuracy": 0.08449074074074074,
        "total": 864,
        "correct": 73
      }
    },
    "invalid_predictions": 1,
    "invalid_rate": 6.613756613756614e-05
  }
}