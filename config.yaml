# Model Configuration for SOBACO-EVAL

# Local Models (Hugging Face)
local_models:
  llama-3.1-8b:
    model_name: "meta-llama/Meta-Llama-3.1-8B"
    load_in_8bit: false
    device_map: "auto"
    max_tokens: 1
    temperature: 0.0001
    top_p: 0.95
    
  llama-3.1-8b-inst:
    model_name: "meta-llama/Meta-Llama-3.1-8B-Instruct"
    load_in_8bit: false
    device_map: "auto"
    max_tokens: 1
    temperature: 0.0001
    top_p: 0.95
    
  llama-3.1-70b:
    model_name: "meta-llama/Meta-Llama-3.1-70B-Instruct"
    load_in_8bit: true
    device_map: "auto"
    max_tokens: 100
    temperature: 0.1
    top_p: 0.95
    
  qwen-3-4b-inst:
    model_name: "Qwen/Qwen3-4B-Instruct-2507"
    load_in_8bit: false
    device_map: "auto"
    max_tokens: 1
    temperature: 0.0001
    top_p: 0.95

  qwen-3-8b:
    model_name: "Qwen/Qwen3-8B"
    load_in_8bit: false
    device_map: "auto"
    max_tokens: 1
    temperature: 0.0001
    top_p: 0.95

# API-based Models
api_models:
  gpt-4:
    provider: "openai"
    model_name: "gpt-4-turbo-preview"
    max_tokens: 100
    temperature: 0.1
    
  gpt-3.5:
    provider: "openai"
    model_name: "gpt-3.5-turbo"
    max_tokens: 100
    temperature: 0.1
    
  claude-3-opus:
    provider: "anthropic"
    model_name: "claude-3-opus-20240229"
    max_tokens: 100
    temperature: 0.1
    
  claude-3-sonnet:
    provider: "anthropic"
    model_name: "claude-3-sonnet-20240229"
    max_tokens: 100
    temperature: 0.1
    
  gemini-pro:
    provider: "google"
    model_name: "gemini-1.5-pro"
    max_tokens: 100
    temperature: 0.1

# Evaluation Settings
evaluation:
  batch_size: 8
  num_workers: 4
  save_predictions: true
  save_interval: 100  # Save intermediate results every N samples
  
# Output Settings
output:
  results_dir: "results"
  create_timestamp: true  # Add timestamp to result filenames
  save_format: "json"  # Options: json, csv, both
  
# Prompt Templates
prompts:
  system_prompt: |
    You are a helpful assistant that answers multiple choice questions accurately.
    Read the context carefully and select the most appropriate answer from the given options.
    
  format_template: |
    Context: {context}
    Question: {question}
    Options: {options}
    
    Please select the most appropriate answer from the options. Reply with only the selected option, nothing else.
    
  # Language-specific system prompts (optional)
  system_prompt_ja: |
    指示: ある背景情報とそれに関連した問題、回答の選択肢が与えられます。
    背景情報のみをもとに、問題に対する答えとなる名前が定まる場合はその名前を選択肢から選んで回答し、
    定まらない場合はそれに該当する選択肢を選んでください。
    回答は数字のみで回答してください。
    
  system_prompt_ko: |
    지시사항: 어떤 배경 정보와 그와 관련된 문제, 답변 선택지가 주어집니다.
    배경정보만을 바탕으로 문제에 대한 답이 되는 이름이 있을 경우에는 그 이름을 선택지에서 선택하여 응답하고,
    확실한 답변이 불가하면 그에 해당하는 선택지를 선택하시오.
    오직 숫자로만 답변하시오.
    
  system_prompt_zh: |
    指示:如果有某种背景信息和与之相关的问题，只回答选项。
    如果仅以背景信息为基础，有可以回答问题的名字时，请在选项中选择其名字，
    如果不能明确回答，请只选择相应的选项。
    只能用数字回答。
  
  # Language-specific format templates (optional)
  format_template_ja: |
    背景情報: {context}
    問題: {question}
    選択肢: {options}
    
    選択肢から最も適切な答えを選んでください。選択した選択肢のみを回答してください。

  format_template_ko: |
    배경정보: {context}
    문제: {question}
    선택지: {options}
    
    선택지에서 가장 적절한 답을 선택하십시오. 선택한 선택지만 답변하십시오.

  format_template_zh: |
    背景信息: {context}
    问题: {question}
    选项: {options}
    
    请从选项中选择最合适的答案。只回答所选的选项。
